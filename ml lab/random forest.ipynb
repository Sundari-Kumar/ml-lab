{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7526f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cse-03\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cse-03\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  The pasta was cooked to perfection and tasted ...          1\n",
      "1        I had the worst burger ever, totally burnt.          0\n",
      "2                 The sushi was fresh and delicious.          1\n",
      "3                   Soup was cold and had no flavor.          0\n",
      "4                Absolutely loved the desserts here!          1\n",
      "Best Model Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "\n",
      "Sample Review: pasta tasty\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Sample Review: couldn’t finish taste horrible\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Sample Review: every bite explosion flavor loved\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Sample Review: worth money disappointing meal\n",
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# ✅ Step 1: Load the Dataset\n",
    "df = pd.read_csv(\"food_reviews.csv\") # Load dataset\n",
    "print(df.head()) # Display first few rows\n",
    "\n",
    "# ✅ Step 2: Improved Text Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text) # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text) # Remove numbers\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words] # Lemmatization & Stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)\n",
    "\n",
    "# ✅ Step 3: Convert Text to Numerical Features (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Increased feature size\n",
    "X = vectorizer.fit_transform(df[\"cleaned_review\"])\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "# ✅ Step 4: Split Data into Train and Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Step 5: Hyperparameter Optimization with Class Weight Handling\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100],  # Reduced to prevent overfitting\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"min_samples_split\": [5, 10]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42, class_weight=\"balanced\")  # Handle class imbalance\n",
    "\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=3, scoring=\"accuracy\", n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# ✅ Step 6: Model Evaluation\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ✅ Step 7: Sample Prediction\n",
    "sample_texts = [\n",
    "    \"The pasta was very tasty.\",\n",
    "    \"I couldn’t finish it, the taste was horrible.\",\n",
    "    \"Every bite was an explosion of flavors, loved it!\",\n",
    "    \"Not worth the money, very disappointing meal.\"\n",
    "]\n",
    "sample_texts = [preprocess_text(text) for text in sample_texts]\n",
    "sample_vectorized = vectorizer.transform(sample_texts)\n",
    "sample_predictions = best_rf.predict(sample_vectorized)\n",
    "\n",
    "for text, prediction in zip(sample_texts, sample_predictions):\n",
    "    print(f\"\\nSample Review: {text}\")\n",
    "    print(\"Predicted Sentiment:\", \"Positive\" if prediction == 1 else \"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "744a5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\cse-03\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.16-cp37-cp37m-win_amd64.whl.metadata (41 kB)\n",
      "     -------------------------------------- 42.0/42.0 kB 406.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     -------------------------------------- 57.7/57.7 kB 752.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\cse-03\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\cse-03\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cse-03\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->click->nltk) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\cse-03\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->click->nltk) (4.7.1)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp37-cp37m-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 269.6/269.6 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 98.2/98.2 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.5/78.5 kB 726.6 kB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.8.1 regex-2024.4.16 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4fafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
